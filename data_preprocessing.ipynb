{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1P8h-_TBuKFw1uUnKbkjNgtiW6RJLL-rl","authorship_tag":"ABX9TyPs8ITOGZn3FfZKuLvX8EU8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Gey31c7kfih2"},"outputs":[],"source":["!pip install snntorch"]},{"cell_type":"markdown","source":["# **1. Setting up**"],"metadata":{"id":"qoImVGasq8o5"}},{"cell_type":"code","source":["# imports\n","import snntorch as snn\n","from snntorch import utils\n","\n","import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n"],"metadata":{"id":"5U8zJciEfrjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Parameters\n","batch_size=128\n","data_path='/tmp/data/fashion-mnist'\n","num_classes = 10  # fashion MNIST has 10 output classes\n","\n","# Torch Variables\n","dtype = torch.float"],"metadata":{"id":"KhltGzVVk9i8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a transform\n","transform = transforms.Compose([\n","            transforms.Resize((28,28)),\n","            transforms.Grayscale(),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0,), (1,))])\n","\n","fmnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transform)\n","fmnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transform)"],"metadata":{"id":"FBAV-g-3oK02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OPTIONAL: for experimenting\n","# Only using a small subset of dataset\n","\n","subset = 10 # 60k -> 6k\n","fmnist_train = utils.data_subset(fmnist_train, subset)"],"metadata":{"id":"iHMKA-wqplFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loader serves minibatches of batch_size\n","\n","train_loader = DataLoader(fmnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_loader = DataLoader(fmnist_test, batch_size=batch_size, shuffle=True, drop_last=True)\n","# dropping last batch in case not divisible by batch size"],"metadata":{"id":"zBEzIygCp_Lz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_loader)"],"metadata":{"id":"LbpVtCFat0TY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Data encoding**"],"metadata":{"id":"8N-2Vk-FrG_-"}},{"cell_type":"markdown","source":["3 encoding options\n","1. Rate coding: input features -> spiking freq.\n","2. Latency coding: input features -> spiking time (more noise, less heavy)\n","3. Delta modulation: temporal change of input features -> spikes (used for when there's a threshold of an event change big *enough* to matter)"],"metadata":{"id":"I8LWyUox18Kz"}},{"cell_type":"code","source":["from snntorch import spikegen\n","\n","# num_steps represents the time steps/spiking sequence length\n","num_steps = 100 # higher num_steps -> spiking prob. closer to raw value"],"metadata":{"id":"-aeA2-6arJxU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we choose rate coding... \\\\\n","&nbsp;&nbsp;&nbsp;&nbsp;>Bright pixels have lower spiking prob. \\\\\n","&nbsp;&nbsp;&nbsp;&nbsp;>Dark pixels have higher spiking prob."],"metadata":{"id":"eg6Lho7KtJcy"}},{"cell_type":"code","source":["# Iterate through minibatches\n","data = iter(train_loader)\n","input_it, label_it = next(data)\n","\n","# Encode using rate coding\n","spike_data = spikegen.rate(input_it, num_steps=num_steps) # default gain=1.0 (spiking freq)\n","\n","print(spike_data.size())    # structure should be [num_steps, batch_size, input dims]"],"metadata":{"id":"dolEOPkrtMmN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **3. Visualization (optional)**"],"metadata":{"id":"IwmgMnFqvaW5"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import snntorch.spikeplot as splt\n","from IPython.display import HTML"],"metadata":{"id":"U1FlO4Advh8c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract a single sample by indexing into the first image of the first batch\n","spike_data_sample = spike_data[:, 0, 0]\n","print(spike_data_sample.size())\n","spike_data_sample.data"],"metadata":{"collapsed":true,"id":"RCBAByhgwV-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots()\n","anim = splt.animator(spike_data_sample, fig, ax)\n","HTML(anim.to_html5_video())"],"metadata":{"collapsed":true,"id":"URhewS4pxnAg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spike_data = spikegen.rate(input_it, num_steps=num_steps, gain=0.75)\n","spike_data_sample2 = spike_data[:, 0, 0]\n","fig, ax = plt.subplots()\n","anim = splt.animator(spike_data_sample2, fig, ax)\n","HTML(anim.to_html5_video())"],"metadata":{"collapsed":true,"id":"iRUqMQMWy5mR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(facecolor=\"w\")\n","plt.subplot(1,2,1)\n","plt.imshow(spike_data_sample.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n","plt.axis('off')\n","plt.title('Gain = 1')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(spike_data_sample2.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n","plt.axis('off')\n","plt.title('Gain = 0.25')\n","\n","plt.show() # higher gain -> clearer reconstruction of image"],"metadata":{"collapsed":true,"id":"pJ_VRjrz0m3i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next, we implement the model!"],"metadata":{"id":"zwPVEK091oWe"}}]}