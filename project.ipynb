{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMpk5Ee0FyX1HLAxF28DiTH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b3o80CEYRSC","executionInfo":{"status":"ok","timestamp":1754601506608,"user_tz":420,"elapsed":4424,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}},"outputId":"9add1ba6-3c4b-45a8-fae0-a4f55cdc961f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting snntorch\n","  Downloading snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n","Downloading snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: snntorch\n","Successfully installed snntorch-0.9.4\n"]}],"source":["!pip install snntorch"]},{"cell_type":"code","source":["import snntorch as snn\n","from snntorch import spikeplot as splt\n","from snntorch import spikegen\n","\n","import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from snntorch import utils"],"metadata":{"id":"toyu7sJoZk4R","executionInfo":{"status":"ok","timestamp":1754601714431,"user_tz":420,"elapsed":4910,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Training Parameters\n","batch_size=128\n","data_path='/tmp/data/fashion-mnist'\n","num_classes = 10  # fashion MNIST has 10 output classes\n","\n","dtype = torch.float\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","# print(device)"],"metadata":{"id":"meE5NQr2ZwZR","executionInfo":{"status":"ok","timestamp":1754601716035,"user_tz":420,"elapsed":4,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Define a transform\n","transform = transforms.Compose([\n","            transforms.Resize((28,28)),\n","            transforms.Grayscale(),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0,), (1,))])\n","\n","fmnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transform)\n","fmnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transform)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GzT32VlZaKPZ","executionInfo":{"status":"ok","timestamp":1754601743986,"user_tz":420,"elapsed":6686,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}},"outputId":"898dcb94-3054-45f1-854e-c8925b895a08"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 26.4M/26.4M [00:02<00:00, 12.2MB/s]\n","100%|██████████| 29.5k/29.5k [00:00<00:00, 210kB/s]\n","100%|██████████| 4.42M/4.42M [00:01<00:00, 3.89MB/s]\n","100%|██████████| 5.15k/5.15k [00:00<00:00, 9.89MB/s]\n"]}]},{"cell_type":"code","source":["# Loader serves minibatches of batch_size\n","\n","train_loader = DataLoader(fmnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_loader = DataLoader(fmnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"],"metadata":{"id":"X8ecJbPvahXP","executionInfo":{"status":"ok","timestamp":1754605813074,"user_tz":420,"elapsed":9,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# Time to combine to build our model\n","class LeakySurrogate(nn.Module):\n","  def __init__(self, beta, threshold=1) -> None:\n","    super(LeakySurrogate, self).__init__()\n","\n","    # Initialize decay rate constant and threshold\n","    self.beta = beta\n","    self.threshold = threshold # R=1 to simplify\n","    self.spike_grad = self.Arctan.apply\n","    # self._init_mem()\n","\n","  def forward(self, input_, mem):\n","    # Define forward pass\n","    spike = self.spike_grad(mem-self.threshold) # spike = 0.0 or 1.0\n","    reset = (self.beta * spike * self.threshold).detach() # reset membrane potential\n","    mem = self.beta * mem + input_ - reset # remove reset before backward pass\n","    return spike, mem\n","\n","  def _init_mem(self):\n","        mem = torch.zeros(0)\n","        self.register_buffer(\"mem\", mem, False)\n","\n","  def init_leaky(self, input_):\n","    # Reset membrane\n","    return torch.zeros_like(input_)\n","\n","  # Autograd func\n","  @staticmethod\n","  class Arctan(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, mem):\n","      # Returns 1.0 if over threshold, 0.0 otherwise\n","      ctx.save_for_backward(mem)\n","      return (mem > 0).float()\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","      # Custom to avoid dead neuron\n","      (mem, ) = ctx.saved_tensors  # Retrieve\n","      grad_input = 1 / (1+(np.pi*mem).pow_(2)) * grad_output # Smoothing, modifying tensor in place for space efficiency\n","      return grad_input"],"metadata":{"id":"CoyBZViHZrTt","executionInfo":{"status":"ok","timestamp":1754607757439,"user_tz":420,"elapsed":40,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["# Network arch\n","num_inputs = 28*28\n","num_hidden = 1000\n","num_outputs = 10\n","\n","# Temporal dynamics\n","num_steps = 25\n","beta = 0.95"],"metadata":{"id":"Z0G6Mk7Naukb","executionInfo":{"status":"ok","timestamp":1754605820645,"user_tz":420,"elapsed":33,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Define network\n","class Network(nn.Module):\n","  def __init__(self) -> None:\n","    super().__init__()\n","\n","    # Initialize layers\n","    self.fc1 = nn.Linear(num_inputs, num_hidden)  # transform input pixels\n","    self.lif1 = LeakySurrogate(beta)              # weighted input over time\n","    self.fc2 = nn.Linear(num_hidden, num_outputs) # transform output spikes\n","    self.lif2 = LeakySurrogate(beta)              # weighted spikes over time\n","\n","  def forward(self, x):\n","\n","    # At t=0\n","    mem1 = None\n","    mem2 = None\n","\n","    # Save final layer\n","    spk2_rec = []\n","    mem2_rec = []\n","\n","    for step in range(num_steps):\n","      # Apply layers\n","\n","      cur1 = self.fc1(x)\n","\n","      if mem1 is None:\n","        mem1 = self.lif1.init_leaky(cur1)\n","      spk1, mem1 = self.lif1(cur1, mem1)\n","      # print(\"spk1 shape:\", spk1.shape)\n","\n","      cur2 = self.fc2(spk1)\n","\n","      if mem2 is None:\n","        mem2 = self.lif2.init_leaky(cur2)\n","      spk2, mem2 = self.lif2(cur2, mem2)\n","\n","      # Save for recording\n","      spk2_rec.append(spk2)\n","      mem2_rec.append(mem2)\n","    return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",""],"metadata":{"id":"OGkm9Jn-a159","executionInfo":{"status":"ok","timestamp":1754607829025,"user_tz":420,"elapsed":7,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["# Load network onto cuda\n","net = Network().to(device)"],"metadata":{"id":"qXhHF85_a9G3","executionInfo":{"status":"ok","timestamp":1754607833263,"user_tz":420,"elapsed":10,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["# Accuracy metrics\n","\n","def print_batch_accuracy(data, targets, train=False):\n","    output, _ = net(data.view(batch_size, -1))\n","    _, idx = output.sum(dim=0).max(1)\n","    acc = np.mean((targets == idx).detach().cpu().numpy())\n","\n","    if train:\n","        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n","    else:\n","        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n","\n","def train_printer(\n","    data, targets, epoch,\n","    counter, iter_counter,\n","        loss_hist, test_loss_hist, test_data, test_targets):\n","    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n","    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n","    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n","    print_batch_accuracy(data, targets, train=True)\n","    print_batch_accuracy(test_data, test_targets, train=False)\n","    print(\"\\n\")"],"metadata":{"id":"CVIQTqDPbSea","executionInfo":{"status":"ok","timestamp":1754606958391,"user_tz":420,"elapsed":18,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# Loss func\n","loss = nn.CrossEntropyLoss()\n","\n","# Optimizer\n","optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))"],"metadata":{"id":"4sxxDN5rbX42","executionInfo":{"status":"ok","timestamp":1754605828290,"user_tz":420,"elapsed":4,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["# Training params\n","num_epochs = 1\n","loss_hist = []\n","test_loss_hist = []\n","counter = 0"],"metadata":{"id":"f8DPsm99cdi_","executionInfo":{"status":"ok","timestamp":1754605829509,"user_tz":420,"elapsed":30,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["net.train()\n","\n","# Outer training loop\n","for epoch in range(num_epochs):\n","    iter_counter = 0\n","    train_batch = iter(train_loader)\n","\n","    # Minibatch training loop\n","    for data, targets in train_batch:\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        # forward pass\n","        spk_rec, mem_rec = net(data.view(batch_size, -1))\n","\n","        # initialize the loss & sum over time\n","        loss_val = torch.zeros((1), dtype=dtype, device=device)\n","        for step in range(num_steps):\n","            loss_val += loss(mem_rec[step], targets)\n","\n","        # Gradient calculation + weight update\n","        optimizer.zero_grad()\n","        loss_val.backward()\n","        optimizer.step()\n","\n","        # Store loss history for future plotting\n","        loss_hist.append(loss_val.item())\n","\n","        # Test set\n","        with torch.no_grad():\n","            net.eval()\n","            test_data, test_targets = next(iter(test_loader))\n","            test_data = test_data.to(device)\n","            test_targets = test_targets.to(device)\n","\n","            # Test set forward pass\n","            test_spk, test_mem = net(test_data.view(batch_size, -1))\n","\n","            # Test set loss\n","            test_loss = torch.zeros((1), dtype=dtype, device=device)\n","            for step in range(num_steps):\n","                test_loss += loss(test_mem[step], test_targets)\n","            test_loss_hist.append(test_loss.item())\n","\n","            # Print train/test loss/accuracy\n","            if counter % 50 == 0:\n","                train_printer(\n","                    data, targets, epoch,\n","                    counter, iter_counter,\n","                    loss_hist, test_loss_hist,\n","                    test_data, test_targets)\n","            counter += 1\n","            iter_counter +=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vo9RjGclcgNU","executionInfo":{"status":"ok","timestamp":1754607905864,"user_tz":420,"elapsed":46905,"user":{"displayName":"Skyler Han","userId":"07084454428309069956"}},"outputId":"75b2d9d2-301b-4083-bc5b-2b8bbc22a73e"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Iteration 9\n","Train Set Loss: 61.69\n","Test Set Loss: 62.13\n","Train set accuracy for a single minibatch: 13.28%\n","Test set accuracy for a single minibatch: 17.19%\n","\n","\n","Epoch 0, Iteration 59\n","Train Set Loss: 64.37\n","Test Set Loss: 61.93\n","Train set accuracy for a single minibatch: 7.81%\n","Test set accuracy for a single minibatch: 12.50%\n","\n","\n","Epoch 0, Iteration 109\n","Train Set Loss: 62.54\n","Test Set Loss: 60.52\n","Train set accuracy for a single minibatch: 10.16%\n","Test set accuracy for a single minibatch: 10.16%\n","\n","\n","Epoch 0, Iteration 159\n","Train Set Loss: 65.42\n","Test Set Loss: 61.18\n","Train set accuracy for a single minibatch: 11.72%\n","Test set accuracy for a single minibatch: 14.06%\n","\n","\n","Epoch 0, Iteration 209\n","Train Set Loss: 62.23\n","Test Set Loss: 63.95\n","Train set accuracy for a single minibatch: 7.81%\n","Test set accuracy for a single minibatch: 13.28%\n","\n","\n","Epoch 0, Iteration 259\n","Train Set Loss: 61.91\n","Test Set Loss: 61.84\n","Train set accuracy for a single minibatch: 7.81%\n","Test set accuracy for a single minibatch: 8.59%\n","\n","\n","Epoch 0, Iteration 309\n","Train Set Loss: 59.20\n","Test Set Loss: 59.32\n","Train set accuracy for a single minibatch: 12.50%\n","Test set accuracy for a single minibatch: 14.06%\n","\n","\n","Epoch 0, Iteration 359\n","Train Set Loss: 61.41\n","Test Set Loss: 62.64\n","Train set accuracy for a single minibatch: 8.59%\n","Test set accuracy for a single minibatch: 8.59%\n","\n","\n","Epoch 0, Iteration 409\n","Train Set Loss: 62.49\n","Test Set Loss: 60.25\n","Train set accuracy for a single minibatch: 11.72%\n","Test set accuracy for a single minibatch: 12.50%\n","\n","\n","Epoch 0, Iteration 459\n","Train Set Loss: 61.36\n","Test Set Loss: 61.39\n","Train set accuracy for a single minibatch: 11.72%\n","Test set accuracy for a single minibatch: 8.59%\n","\n","\n"]}]}]}